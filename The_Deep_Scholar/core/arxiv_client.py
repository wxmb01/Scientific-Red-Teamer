# -*- coding: utf-8 -*-
"""
ã€è§¦æ‰‹æ¨¡å—ã€‘arXiv Client (ç½‘ç»œå¢å¼ºç‰ˆ)
åŠŸèƒ½ï¼šæœç´¢è®ºæ–‡ï¼Œä¸‹è½½ PDFï¼Œæå–å…ƒæ•°æ®ã€‚
å·²é›†æˆï¼šSSL ä¿®å¤ + å¼ºåˆ¶ä»£ç†ã€‚
"""
import arxiv
import os
import ssl

# ================= ğŸš‘ ç½‘ç»œæ€¥æ•‘åŒ… =================
# 1. SSL è¯ä¹¦ä¿®å¤
ssl._create_default_https_context = ssl._create_unverified_context

# ================= ğŸš‘ ç½‘ç»œæ€¥æ•‘åŒ… =================
# ... (ä¸Šé¢çš„ SSL ä»£ç ä¸ç”¨åŠ¨)

# ğŸ‘‡ ä¿®æ”¹è¿™ä¸€è¡Œï¼æŠŠ 7890 æ”¹æˆ 7897
PROXY = "http://127.0.0.1:7897" 

os.environ["http_proxy"] = PROXY
os.environ["https_proxy"] = PROXY
# =================================================
# è®¾å®šä¸‹è½½ç›®å½•
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
DOWNLOAD_DIR = os.path.join(PROJECT_ROOT, "workspace")

def search_papers(query, max_results=3):
    """
    æœç´¢å¹¶ä¸‹è½½è®ºæ–‡
    """
    if not os.path.exists(DOWNLOAD_DIR):
        os.makedirs(DOWNLOAD_DIR)

    print(f"ğŸ” [ä»£ç†å·²å¼€å¯] æ­£åœ¨ arXiv æœç´¢: '{query}' ...")
    
    # æ„é€ å®¢æˆ·ç«¯ (è°ƒæ•´è¶…æ—¶æ—¶é—´)
    client = arxiv.Client(
        page_size=max_results,
        delay_seconds=3.0,
        num_retries=3
    )
    
    search = arxiv.Search(
        query=query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.Relevance
    )

    results = []
    
    try:
        # è¿™é‡Œçš„ results() æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œæˆ‘ä»¬éœ€è¦å°è¯•éå†å®ƒ
        for r in client.results(search):
            # æ¸…æ´—æ–‡ä»¶å
            safe_title = "".join([c for c in r.title if c.isalnum() or c in " ._-"]).strip()
            filename = f"{r.entry_id.split('/')[-1]}_{safe_title[:50]}.pdf"
            file_path = os.path.join(DOWNLOAD_DIR, filename)
            
            paper_info = {
                "title": r.title,
                "summary": r.summary,
                "path": file_path
            }
            
            # ä¸‹è½½é€»è¾‘
            if not os.path.exists(file_path):
                print(f"â¬‡ï¸ ä¸‹è½½ä¸­: {r.title[:30]}...")
                r.download_pdf(dirpath=DOWNLOAD_DIR, filename=filename)
            else:
                print(f"â© å·²å­˜åœ¨: {r.title[:30]}...")
                
            results.append(paper_info)
            
    except Exception as e:
        print(f"âš ï¸ ç½‘ç»œè¿æ¥é”™è¯¯: {e}")
        # å¦‚æœæ˜¯ Streamlit è°ƒç”¨ï¼Œå¯ä»¥åœ¨è¿™é‡ŒæŠ›å‡ºé”™è¯¯æˆ–è€…è®°å½•æ—¥å¿—

    print(f"âœ… æˆåŠŸè·å– {len(results)} ç¯‡è®ºæ–‡ã€‚")
    return results

if __name__ == "__main__":
    # è‡ªæµ‹
    search_papers("Generative AI", max_results=1)